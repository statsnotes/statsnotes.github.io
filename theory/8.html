<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Statistics for Social Scientists</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="8_files/libs/clipboard/clipboard.min.js"></script>
<script src="8_files/libs/quarto-html/quarto.js"></script>
<script src="8_files/libs/quarto-html/popper.min.js"></script>
<script src="8_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="8_files/libs/quarto-html/anchor.min.js"></script>
<link href="8_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="8_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="8_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="8_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="8_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: true
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body>

<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Statistics for Social Scientists</h1>
            <p class="subtitle lead">Lesson 1.8: Inference with the OLS Estimator</p>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta">

      
    
      
    </div>
    
  
  </header><div id="quarto-content" class="page-columns page-rows-contents page-layout-article toc-left">
<div id="quarto-sidebar-toc-left" class="sidebar toc-left">
  <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="99">
    <h2 id="toc-title">Lesson 1.8: Inference with the OLS Estimator</h2>
   
  <ul class="collapse">
  <li><a href="#variance-of-the-ols-estimator" id="toc-variance-of-the-ols-estimator" class="nav-link active" data-scroll-target="#variance-of-the-ols-estimator">1.8.1: Variance of the OLS Estimator</a></li>
  <li><a href="#standard-errors-and-multicollinearity" id="toc-standard-errors-and-multicollinearity" class="nav-link" data-scroll-target="#standard-errors-and-multicollinearity">1.8.2: Standard Errors and Multicollinearity</a></li>
  <li><a href="#statistical-inference-in-multiple-linear-regression" id="toc-statistical-inference-in-multiple-linear-regression" class="nav-link" data-scroll-target="#statistical-inference-in-multiple-linear-regression">1.8.3: Statistical Inference in Multiple Linear Regression</a></li>
  <li><a href="#hypothesis-testing-with-more-than-one-coefficient" id="toc-hypothesis-testing-with-more-than-one-coefficient" class="nav-link" data-scroll-target="#hypothesis-testing-with-more-than-one-coefficient">1.8.4: Hypothesis Testing with More than One Coefficient</a></li>
  <li><a href="#heteroscedasticity-and-robust-standard-errors" id="toc-heteroscedasticity-and-robust-standard-errors" class="nav-link" data-scroll-target="#heteroscedasticity-and-robust-standard-errors">1.8.5: Heteroscedasticity and Robust Standard Errors</a></li>
  <li><a href="#introduction-to-asymptotic-properties" id="toc-introduction-to-asymptotic-properties" class="nav-link" data-scroll-target="#introduction-to-asymptotic-properties">1.8.6: Introduction to Asymptotic Properties</a></li>
  <li><a href="#asymptotic-consistency-of-ols" id="toc-asymptotic-consistency-of-ols" class="nav-link" data-scroll-target="#asymptotic-consistency-of-ols">1.8.7: Asymptotic Consistency of OLS</a></li>
  <li><a href="#implementation-in-r" id="toc-implementation-in-r" class="nav-link" data-scroll-target="#implementation-in-r">Implementation in R</a>
  <ul class="collapse">
  <li><a href="#hypothesis-testing" id="toc-hypothesis-testing" class="nav-link" data-scroll-target="#hypothesis-testing">Hypothesis Testing</a></li>
  <li><a href="#confidence-intervals-1" id="toc-confidence-intervals-1" class="nav-link" data-scroll-target="#confidence-intervals-1">Confidence Intervals</a></li>
  <li><a href="#f-tests-of-nested-models" id="toc-f-tests-of-nested-models" class="nav-link" data-scroll-target="#f-tests-of-nested-models">F-Tests of Nested Models</a></li>
  </ul></li>
  </ul>
</nav>
</div>
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
</div>
<main class="content quarto-banner-title-block" id="quarto-document-content">





<p>This lesson covers the following topics:</p>
<ul>
<li>How standard errors are calculated under the assumption of homoscedasticity.</li>
<li>How hypothesis tests (including multiple coefficients at once) and confidence intervals are conducted.</li>
<li>How the presence of heteroscedasticity affects our standard errors, and how we can adjust for this.</li>
<li>How OLS estimates behave as our sample size increases (asymptotic properties).</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>This first part of this lesson will mirror the second half of <a href="https://statsnotes.github.io/theory/5.html">lesson 1.5</a>, but will adjust the inference of bivariate regression to multiple regression, and introduce new topics. I recommend a strong understanding of those topics before starting this chapter.</p>
</div>
</div>
<p><br></p>
<hr>
<p><a href="https://statsnotes.github.io">Homepage</a></p>
<section id="variance-of-the-ols-estimator" class="level1">
<h1>1.8.1: Variance of the OLS Estimator</h1>
<p>We have proved that OLS is unbiased under 4 conditions in the last lesson.</p>
<p>However, if we recall from <a href="https://statsnotes.github.io/theory/2.html#properties-of-estimators">1.2.8</a>, unbiasedness is not the only thing we care about in an estimator. We also care about the estimators variance.</p>
<ul>
<li>This was further discussed in <a href="https://statsnotes.github.io/theory/5.html#variance-of-the-ols-estimator-and-homoscedasticity">1.5.4</a> about the simple linear regression model.</li>
</ul>
<p>Just like in simple linear regression, an additional condition, homoscedasticity, can be added to the 4 existing conditions to determine that OLS is the linear estimator with the least variance (see <a href="https://statsnotes.github.io/theory/5.html#variance-of-the-ols-estimator-and-homoscedasticity">1.5.4</a> for more details on homoscedasticity):</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Definition: Gauss-Markov Theorem
</div>
</div>
<div class="callout-body-container callout-body">
<p>The Gauss-Markov Theorem states that under 5 conditions, the OLS estimator is the Best Linear Unbiased Estimator (BLUE) for <span class="math inline">\beta_j</span>, being the unbiased linear estimator with the least variance.</p>
<ul>
<li><strong>MLR.1 (Linearity in Parameters)</strong>: The parameters of the model are linear.</li>
<li><strong>MLR.2 (Random Sampling)</strong>: All observations in our sample are randomly sampled from the population.</li>
<li><strong>MLR.3 (No Perfect Mutlicollinearity)</strong>: There are no exact linear relationships among variables (where correlation coefficient equals 1).</li>
<li><strong>MLR.4 (Zero Conditional Mean)</strong>. The error term <span class="math inline">u</span> has an expectation of 0, given any value of <span class="math inline">x_j</span> for any explanatory variable.</li>
<li><strong>MLR.5 (Homoscedasticity)</strong>: The error term has the same variance given any value of <span class="math inline">x</span>: <span class="math inline">Var(u|x_1, \dots, x_k) = \sigma^2</span>.</li>
</ul>
</div>
</div>
<p><br></p>
<p>Assuming homoscedasticity is met, we know <span class="math inline">Var(u|x_1, \dots, x_k) = \sigma^2</span>.</p>
<ul>
<li>When homoscedasticity is not met, nothing in this section applies. See 1.8.4 for more information on how to do estimates when this is violated.</li>
</ul>
<p>Let us find the variance of OLS estimates (we will use <span class="math inline">\hat\beta_1</span> for simplicity, but this applies to any other coefficient <span class="math inline">\hat\beta_1 , \dots, \hat\beta_k</span>. In proving unbiasedness of OLS in <a href="https://statsnotes.github.io/theory/7.html#proof-of-unbiasedness-of-ols-under-gauss-markov">1.7.3</a>, we got to this stage:</p>
<p><span class="math display">
\hat\beta_1 = \beta_1 + \frac{\sum_{i=1}^n \widetilde{r_{1i}} u_i}{\sum_{i=1}^n \widetilde{r_{1i}}^2}
</span></p>
<p>We know that <span class="math inline">\beta_1</span> is a constant (the true value in the population), so that never changes. Thus, it cannot be the variance in <span class="math inline">\hat\beta_1</span>. Thus, the second part is the variance in <span class="math inline">\hat\beta_1</span>.</p>
<p>Let us define <span class="math inline">w_i</span> as following, as a function of <span class="math inline">x_1, \dots, x_k</span>:</p>
<p><span class="math display">
w_i = \frac{\widetilde{r_{1i}}}{\sum_{i=1}^n\widetilde{r_{1i}}^2}
</span></p>
<p>This allows us to write <span class="math inline">\hat\beta_1</span> as:</p>
<p><span class="math display">
\hat\beta_1 = \beta_1 + \sum\limits_{i=1}^nw_i u_i
</span></p>
<p><br></p>
<p>Thus, we can proceed in the same way as the simple linear regression case (see <a href="https://statsnotes.github.io/theory/5.html#variance-of-the-ols-estimator-and-homoscedasticity">1.5.4</a> for more details):</p>
<p><span class="math display">
\begin{split}
Var(\hat\beta_1|x_1, \dots, x_k) &amp; = Var\left( \sum\limits_{i=1}^nw_i u_i \biggr|x_1, \dots ,x_k \right) \\ &amp; = \sum\limits_{i=1}^n Var(w_i u_i | x_1, \dots, x_k) \\
&amp; = \sum\limits_{i=1}^n w_i^2 \ Var(u_i | x_1, \dots, x_k) \\
&amp; = \sum\limits_{i=1}^n w_i^2 \sigma^2 \\
&amp; = \sigma^2 \sum\limits_{i=1}^n w_i^2
\end{split}
</span></p>
<p>Now, plugging back in <span class="math inline">w_i</span>, we get:</p>
<p><span class="math display">
\begin{split}
Var(\hat\beta_1|x_1, \dots, x_k) &amp; = \sigma^2 \sum\limits_{i=1}^n w_i^2 \\
&amp; = \sigma^2 \sum_{i=1}^n \left( \frac{\widetilde{r_{1i}}}{\sum_{i=1}^n\widetilde{r_{1i}}^2} \right) \\
&amp; = \sigma^2 \frac{\sum_{i=1}^n \widetilde{r_{1i}}}{\sum_{i=1}^n\widetilde{r_{1i}}^2} \\
&amp; = \frac{\sigma^2}{\sum_{i=1}^n \widetilde{r_{1i}}^2}
\end{split}
</span></p>
<p>And assuming homoscedasticity (where <span class="math inline">Var(\hat\beta_1)</span> does not depend on <span class="math inline">x_1, \dots, x_k</span>, we thus know:</p>
<p><span class="math display">
Var(\hat\beta_1) = \frac{\sigma^2}{\sum_{i=1}^n \widetilde{r_{1i}}^2}
</span></p>
<p><br></p>
<p><br></p>
<hr>
<p><a href="https://statsnotes.github.io">Homepage</a></p>
</section>
<section id="standard-errors-and-multicollinearity" class="level1">
<h1>1.8.2: Standard Errors and Multicollinearity</h1>
<p>In the last section, we calculated the variance of the OLS estimates of <span class="math inline">\hat\beta_1</span>.</p>
<p>However, just like we mentioned in <a href="https://statsnotes.github.io/theory/5.html#standard-errors-of-the-ols-estimator">1.5.6</a>, the real value of <span class="math inline">\sigma^2</span> of a regression not calculable. This is an issue because our variance formula has <span class="math inline">\sigma^2</span> in the numerator.</p>
<p>Just like in simple linear regression (see <a href="https://statsnotes.github.io/theory/5.html#standard-errors-of-the-ols-estimator">1.5.6</a>), we can estimate <span class="math inline">\sigma^2</span> by using the residual term <span class="math inline">\hat u_i</span> with a degrees of freedom adjustment.</p>
<p><span class="math display">
\hat\sigma^2 = \frac{SSR}{n-k-1} = \frac{\sum_{i=1}^n \hat u_i^2}{n-k-1}
</span></p>
<ul>
<li>Where <span class="math inline">n</span> is the number of observations in our sample data.</li>
<li>Where <span class="math inline">k</span> is the number of explanatory variables in our model.</li>
</ul>
<p>Thus, with this estimate, we can calculate the <strong>standard errors</strong> (square root of variance) of our estimates of coefficients <span class="math inline">\hat\beta_j</span>.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Definition: Standard Errors for Multiple Linear Regression
</div>
</div>
<div class="callout-body-container callout-body">
<p>The standard error for the coefficient <span class="math inline">\hat\beta_j</span> from an OLS estimator in multiple linear regression is:</p>
<p><span class="math display">
\widehat{se}(\hat\beta_j) = \frac{\hat\sigma}{\sqrt{\sum_{i=1}^n \widetilde{r_{1i}}^2}}
</span></p>
<ul>
<li>We will never calculate this by hand, we will use a statistical software to do this.</li>
</ul>
<p>Where <span class="math inline">\hat\sigma</span> is defined as:</p>
<p><span class="math display">
\hat\sigma = \sqrt{\frac{SSR}{n-k-1}} = \sqrt{\frac{\sum_{i=1}^n \hat u_i^2}{n-k-1}}
</span></p>
</div>
</div>
<p><br></p>
<section id="multicollinearity" class="level3">
<h3 class="anchored" data-anchor-id="multicollinearity">Multicollinearity</h3>
<p>Notice how the denominator contains <span class="math inline">\sum\widetilde{r_{1i}}^2</span>. That means, the smaller <span class="math inline">\sum\widetilde{r_{1i}}^2</span> is, the larger the variance is.</p>
<ul>
<li><span class="math inline">\sum\widetilde{r_{1i}}^2</span> is smaller when our explanatory variable of interest <span class="math inline">x_1</span> is highly correlated with another explanatory variable, since <span class="math inline">\widetilde{r_{1i}}^2</span> represents the part of <span class="math inline">x_1</span> that is uncorrelated with other explanatory variables.</li>
<li>This means that if we have highly correlated explanatory variables, our variance will in our OLS estimates will be high.</li>
</ul>
<p>This is something important to think about when choosing explanatory variables. We want to include all confounding variables, but highly correlated confounders will make our variance very high for our estimates.</p>
<ul>
<li>One way of dealing with this is dimensional reduction techniques, which we will discuss in Part III of the guide dealing with multivariate anlaysis.</li>
</ul>
<p><br></p>
<p><br></p>
<hr>
<p><a href="https://statsnotes.github.io">Homepage</a></p>
</section>
</section>
<section id="statistical-inference-in-multiple-linear-regression" class="level1">
<h1>1.8.3: Statistical Inference in Multiple Linear Regression</h1>
<section id="hypothesis-tests" class="level3">
<h3 class="anchored" data-anchor-id="hypothesis-tests">Hypothesis Tests</h3>
<p>With the standard error, we can conduct hypothesis tests.</p>
<ul>
<li>The procedure is identical to simple linear regression, see <a href="https://statsnotes.github.io/theory/5.html#statistical-inference-in-simple-linear-regression">1.5.7</a>.</li>
<li>The intuition of hypothesis testing was outlined in <a href="https://statsnotes.github.io/theory/2.html#intuition-of-hypothesis-testing">1.2.5</a> and <a href="https://statsnotes.github.io/theory/2.html#implementing-a-hypothesis-test">1.2.6</a>.</li>
</ul>
<p>Our hypotheses will typically be:</p>
<p><span class="math display">
\begin{split}
&amp; H_0 : \beta_j = 0 \\
&amp; H_1: \beta_j ≠ 0
\end{split}
</span></p>
<p>Our t-test statistic will be:</p>
<p><span class="math display">
t = \frac{\hat\beta_j - 0}{\widehat{se}(\hat\beta_j)}
</span></p>
<p>And through a t-distribution, we will calculate the p-values.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Interpretation of p-Values for Regression
</div>
</div>
<div class="callout-body-container callout-body">
<p>The p-value is the probability of getting a test statistic equally or more extreme than the one we got with our sample estimate <span class="math inline">\hat\beta_j</span>, given the null hypothesis is true.</p>
<ul>
<li><p>If <span class="math inline">p&lt;0.05</span>, we believe the probability of the null hypothesis is low enough, such that we reject the null hypothesis (that there is no relationship between <span class="math inline">x_j</span> and <span class="math inline">y</span>), and conclude our alternate hypothesis (that there is a relationship between <span class="math inline">x_j</span> and <span class="math inline">y</span>).</p></li>
<li><p>If <span class="math inline">p&gt;0.05</span>, we cannot reject the null hypothesis, and cannot reject that there is no relationship between <span class="math inline">x_j</span> and <span class="math inline">y</span>.</p></li>
</ul>
</div>
</div>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning!
</div>
</div>
<div class="callout-body-container callout-body">
<p>Note how I have been using the word <strong>relationship</strong>, not causal effect.</p>
<p>Causality is not established through estimators, it is established through a strong experimental design (which we will cover in part II of the course).</p>
</div>
</div>
<p><br></p>
</section>
<section id="confidence-intervals" class="level3">
<h3 class="anchored" data-anchor-id="confidence-intervals">Confidence Intervals</h3>
<p>We can also create confidence intervals of plausible true <span class="math inline">\beta_j</span> values from the population, given our estimate <span class="math inline">\hat\beta_j</span>. The intuition is the same as discussed in <a href="https://statsnotes.github.io/theory/2.html#confidence-intervals">1.2.7</a>.</p>
<p>Just like previously discussed in <a href="https://statsnotes.github.io/theory/2.html#confidence-intervals">1.2.7</a>, the 95% confidence interval has the bounds:</p>
<p><span class="math display">
\hat\beta_j - 1.96 \widehat{se}(\hat\beta_j), \ \hat\beta_j + 1.96 \widehat{se}(\hat\beta_j)
</span></p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Interpretation of Confidence Intervals
</div>
</div>
<div class="callout-body-container callout-body">
<p>The confidence interval means that under repeated sampling and estimating <span class="math inline">\hat\beta_j</span>, 95% of the confidence intervals we construct will include the true <span class="math inline">\beta_j</span> value in the population.</p>
</div>
</div>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Interpretation Warning!
</div>
</div>
<div class="callout-body-container callout-body">
<p>It is very important to note that confidence intervals do not mean a 95% probability that the true <span class="math inline">\beta_1</span> is within any specific confidence interval we calculated.</p>
<p>We cannot know based on one confidence interval, whether it covers or does not cover the true <span class="math inline">\beta_j</span>.</p>
<p>The correct interpretation is that over many samples from the same population, we would expect 95% of our confidence intervals to contain the true <span class="math inline">\beta_j</span> value.</p>
</div>
</div>
<p><br></p>
<p><br></p>
<hr>
<p><a href="https://statsnotes.github.io">Homepage</a></p>
</section>
</section>
<section id="hypothesis-testing-with-more-than-one-coefficient" class="level1">
<h1>1.8.4: Hypothesis Testing with More than One Coefficient</h1>
<p>Sometimes, we want to test more than one coefficient at a time in a hypothesis test.</p>
<ul>
<li>This will be especially obvious why after lesson 1.9.</li>
</ul>
<p>For example, let us say we want to test the statistical significance of <span class="math inline">\hat\beta_2</span> and <span class="math inline">\hat\beta_3</span> at the same time in the following regression model:</p>
<p><span class="math display">
\hat y = \hat\beta_0 + \hat\beta_1x_1 + \hat\beta_2x_2 + \hat\beta_3x_3
</span></p>
<p>What we can do is create two models - the alternate model <span class="math inline">M_a</span>, and the null model <span class="math inline">M_0</span>. The alternate model <span class="math inline">M_a</span> is the model we have above, and the null modle <span class="math inline">M_0</span> is the model without the two coefficients that we want to test (<span class="math inline">\hat\beta_2</span> and <span class="math inline">\hat\beta_3</span>).</p>
<p><span class="math display">
\begin{split}
&amp; M_0: y = \beta_0 + \beta_1x_1 \\
&amp; M_a: y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3x_3
\end{split}
</span></p>
<p>Our statistical test will be to test if the alternative model <span class="math inline">M_a</span> is significantly “better” than our null model <span class="math inline">M_0</span>. If <span class="math inline">M_a</span> is indeed significantly better, than we know that the coefficients <span class="math inline">\hat\beta_2</span> and <span class="math inline">\hat\beta_3</span> together are statistically significant.</p>
<p>Let us generalise this framework.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Definition: F-Test of Nested Models
</div>
</div>
<div class="callout-body-container callout-body">
<p>The F-test of Nested Models allows us to test multiple coefficients at once. It compares two models: <span class="math inline">M_0</span> and <span class="math inline">M_a</span>.</p>
<p><span class="math display">
\begin{split}
&amp; M_0: y = \beta_0 + \beta_1x_1 + \dots + \beta_g x_g \\
&amp; M_a: y = \beta_0 + \beta_1 x_1 + \dots + \beta_g x_g + \beta_{g+1} x_{g+1} + \dots + \beta_kx_k
\end{split}
</span></p>
<ul>
<li>The model <span class="math inline">M_a</span> contains all of the explanatory variables, including the ones we want to test.</li>
<li>The model <span class="math inline">M_0</span> contains the other explanatory variables that are not a part of our test. Model <span class="math inline">M_0</span> must be “nested” in model <span class="math inline">M_a</span>: i.e.&nbsp;all explanatory variables present in <span class="math inline">M_0</span> must also be in <span class="math inline">M_a</span>.</li>
</ul>
<p>The model tests if <span class="math inline">M_a</span> is significantly better than <span class="math inline">M_0</span>. If this is the case, the extra coefficients in <span class="math inline">M_a</span> that we are testing are statistically significant.</p>
</div>
</div>
<p><br></p>
<p>How do we run a F-test of nested models?</p>
<p>Recall the concept of <span class="math inline">R^2</span> discussed in <a href="https://statsnotes.github.io/theory/6.html#r-squared-and-goodness-of-fit">1.6.7</a>. <span class="math inline">R^2</span> describes how much of the variation in <span class="math inline">y</span> our explanatory variables explain.</p>
<p>The F-test uses the <span class="math inline">R^2</span> of the two models, and compares them.</p>
<ul>
<li>If the <span class="math inline">M_a</span> model has a statistically significantly higher <span class="math inline">R^2</span> value than the <span class="math inline">M_0</span> model, then <span class="math inline">M_a</span> is considered statistically significant, and we can conclude that the additional explanatory variables in <span class="math inline">M_a</span> are statistically significant.</li>
</ul>
<p><br></p>
<p>As we know from hypothesis testing (see <a href="https://statsnotes.github.io/theory/2.html#intuition-of-hypothesis-testing">1.2.5</a> and <a href="https://statsnotes.github.io/theory/2.html#implementing-a-hypothesis-test">1.2.6</a> for intuition), we need a test statistic and distribution to run a hypothesis test.</p>
<p>The statistic for a F-test is the F-statistic.</p>
<ul>
<li>Let us define <span class="math inline">R^2_a</span> and <span class="math inline">SSR_a</span> as the <span class="math inline">R^2</span> and sum of squared residuals for model <span class="math inline">M_a</span>.</li>
<li>Let us define <span class="math inline">R^2_0</span> and <span class="math inline">SSR_0</span> as the <span class="math inline">R^2</span> and sum of squared residuals for model <span class="math inline">M_0</span>.</li>
<li>The total number of coefficients in model <span class="math inline">M_a</span> is <span class="math inline">k_a</span>, and for model <span class="math inline">M_0</span>, is <span class="math inline">k_0</span>.</li>
<li>Let us define <span class="math inline">n</span> as the number of observations (should be the same for both models).</li>
</ul>
<p>Our F-statistic is mathematically calculated as:</p>
<p><span class="math display">
F = \frac{(SSR_0 - SSE_a)/(k_a - k_0)}{SSR_a / (n - k_a - 1)}
</span></p>
<p>After calculating our F-statistic, we consult an F-distribution with <span class="math inline">k_a - k_0</span> and <span class="math inline">n-k_a - 1</span> degrees of freedom.</p>
<p>With this distribution, we can obtain our p-value.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Interpretation of p-Values for F-tests
</div>
</div>
<div class="callout-body-container callout-body">
<p>The p-value is the probability of getting a test statistic equally or more extreme than the one we got with our alternate model <span class="math inline">M_a</span>, given the null hypothesis is true.</p>
<ul>
<li><p>If <span class="math inline">p&lt;0.05</span>, we believe the probability of the null hypothesis is low enough, such that we reject the null hypothesis (that <span class="math inline">M_0</span> is a better model), and conclude our alternate hypothesis (that <span class="math inline">M_a</span> is a better model). This also means that the extra coefficients in <span class="math inline">M_a</span> are jointly statistically significant.</p></li>
<li><p>If <span class="math inline">p&gt;0.05</span>, we cannot reject the null hypothesis, and cannot reject that <span class="math inline">M_0</span> is the better model. Thus, the extra coefficients in <span class="math inline">M_a</span> are jointly not statistically significant.</p></li>
</ul>
</div>
</div>
<p><br></p>
<p><br></p>
<hr>
<p><a href="https://statsnotes.github.io">Homepage</a></p>
</section>
<section id="heteroscedasticity-and-robust-standard-errors" class="level1">
<h1>1.8.5: Heteroscedasticity and Robust Standard Errors</h1>
<p><br></p>
<p><br></p>
<hr>
<p><a href="https://statsnotes.github.io">Homepage</a></p>
</section>
<section id="introduction-to-asymptotic-properties" class="level1">
<h1>1.8.6: Introduction to Asymptotic Properties</h1>
<p><br></p>
<hr>
<p><a href="https://statsnotes.github.io">Homepage</a></p>
</section>
<section id="asymptotic-consistency-of-ols" class="level1">
<h1>1.8.7: Asymptotic Consistency of OLS</h1>
<p><br></p>
<hr>
<p><a href="https://statsnotes.github.io">Homepage</a></p>
</section>
<section id="implementation-in-r" class="level1">
<h1>Implementation in R</h1>
<section id="hypothesis-testing" class="level2">
<h2 class="anchored" data-anchor-id="hypothesis-testing">Hypothesis Testing</h2>
<p>To conduct hypothesis testing in a regression, we can use the <em>feols()</em> function from the package <em>fixest</em>, or we can use the base-R function <em>lm()</em>.</p>
<ul>
<li>The syntax is the same for both (at least for now).</li>
<li>The <em>feols()</em> function does have a few advantages for techniques that will be discussed later, especially when it comes to causal inference and econometrics.</li>
</ul>
<p>For the <em>feols()</em> function, we will need the <em>fixest</em> package. Make sure to install it if you have not previously (google how to install R-packages if needed).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(fixest)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><br></p>
<p><strong>Syntax:</strong></p>
<p>For the <em>feols()</em> function, the syntax is as follows:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">feols</span>(y <span class="sc">~</span> x1 <span class="sc">+</span> x2 <span class="sc">+</span> x3, <span class="at">data =</span> mydata)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ul>
<li>Replace <em>model</em> with any name you want to store your regression model in.</li>
<li>Replace <em>y</em> with your outcome variable name, and <em>x1, x2, x3</em> with your explanatory variable name.</li>
<li>You can add more explanatory variables by adding + signs and <em>x4 + x5 …</em> and so on. You can also remove explanatory variables down to only 1.</li>
<li>Replace <em>mydata</em> with the name of your dataframe.</li>
</ul>
<p>The <em>lm()</em> function has the exact same syntax for simple linear regression, except that we replace <em>feols()</em> with <em>lm()</em>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x1 <span class="sc">+</span> x2 <span class="sc">+</span> x3, <span class="at">data =</span> mydata)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><br></p>
<p><strong>Example:</strong></p>
<p>Let us run a regression with outcome variable <em>immatt</em> (attitude towards immigrants), explanatory variables <em>age</em> and <em>educ</em> (years of education), from the dataframe called <em>dta</em>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>my_model <span class="ot">&lt;-</span> <span class="fu">feols</span>(immatt <span class="sc">~</span> age <span class="sc">+</span> educ, <span class="at">data =</span> dta)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(my_model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>OLS estimation, Dep. Var.: immatt
Observations: 33,706
Standard-errors: IID 
             Estimate Std. Error  t value  Pr(&gt;|t|)    
(Intercept) -0.529355   0.026638 -19.8720 &lt; 2.2e-16 ***
age         -0.005175   0.000291 -17.8117 &lt; 2.2e-16 ***
educ         0.063833   0.001381  46.2108 &lt; 2.2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
RMSE: 0.932834   Adj. R2: 0.08225</code></pre>
</div>
</div>
<p>We can see the following output:</p>
<ul>
<li>In the estimate column, we get our intercept estimate <span class="math inline">\hat\beta_0</span>, and our explanatory variables coefficient estimates <span class="math inline">\hat\beta_1</span> and <span class="math inline">\hat\beta_2</span>.</li>
<li>In the standard error column, we get our standard error of our sample estimates.</li>
<li>In the t-value column, we get our t-values for our sample estimates.</li>
<li>In the p-value column, we get our p-values for our sample estimates. Any asterisks * indicate statistical significance.</li>
</ul>
<p>The result is similar with <em>lm()</em>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>my_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(immatt <span class="sc">~</span> age <span class="sc">+</span> educ, <span class="at">data =</span> dta)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(my_model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = immatt ~ age + educ, data = dta)

Residuals:
     Min       1Q   Median       3Q      Max 
-2.97099 -0.58912  0.06513  0.63948  2.77153 

Coefficients:
              Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) -0.5293545  0.0266382  -19.87   &lt;2e-16 ***
age         -0.0051753  0.0002906  -17.81   &lt;2e-16 ***
educ         0.0638327  0.0013813   46.21   &lt;2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.9329 on 33703 degrees of freedom
Multiple R-squared:  0.0823,    Adjusted R-squared:  0.08225 
F-statistic:  1511 on 2 and 33703 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p><br></p>
</section>
<section id="confidence-intervals-1" class="level2">
<h2 class="anchored" data-anchor-id="confidence-intervals-1">Confidence Intervals</h2>
<p><strong>Syntax:</strong></p>
<p>To estimate confidence intervals for our estimates, we will first need to run a regression and hypothesis tests (like above).</p>
<p>Then, we can either manually calculate our confidence intervals (as the standard errors are given in the regression output), or we can use the <em>confint</em> function:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(model_name)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ul>
<li>Replace <em>model_name</em> with whatever variable name you stored your regression in.</li>
</ul>
<p><br></p>
<p><strong>Example:</strong></p>
<p>Let us find the confidence intervals for our estimates in the previous example regression above:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(my_model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                  2.5 %       97.5 %
(Intercept) -0.58156640 -0.477142689
age         -0.00574481 -0.004605809
educ         0.06112520  0.066540126</code></pre>
</div>
</div>
<p>We can see that R outputs the 95% confidence interval lower and upper bounds, for all our estimates <span class="math inline">\hat\beta_0</span> and <span class="math inline">\hat\beta_1</span> and <span class="math inline">\hat\beta_2</span></p>
<p><br></p>
</section>
<section id="f-tests-of-nested-models" class="level2">
<h2 class="anchored" data-anchor-id="f-tests-of-nested-models">F-Tests of Nested Models</h2>
<p><strong>Syntax</strong></p>
<p>For f-tests, we will need two models. Let us save those two regression models as <em>m0</em> (null) and <em>m1</em> (alternate). Then, we can use the <em>anova()</em> function.</p>
<ul>
<li>Note: our models must be created with the <em>lm()</em> function, not the <em>feols()</em> function, to perform an f-test. The reason for this will be explained in the next chapter.</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(m1, m2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><br></p>
<p><strong>Example:</strong></p>
<p>Let us create two different models:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>m0 <span class="ot">&lt;-</span> <span class="fu">lm</span>(immatt <span class="sc">~</span> age, <span class="at">data =</span> dta)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>m1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(immatt <span class="sc">~</span> age <span class="sc">+</span> educ <span class="sc">+</span> female, <span class="at">data =</span> dta)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>So essentially, this F-test will be testing the coefficients of <em>educ</em> and <em>female</em> together.</p>
<p>Now, let us run the F-test:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(m0, m1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Variance Table

Model 1: immatt ~ age
Model 2: immatt ~ age + educ + female
  Res.Df   RSS Df Sum of Sq      F    Pr(&gt;F)    
1  33704 31189                                  
2  33702 29330  2    1858.4 1067.7 &lt; 2.2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
<p>We can see model <em>m1</em> is statistically significant. Thus, the two coefficients of <em>educ</em> and <em>female</em> together are statistically significant.</p>
<ul>
<li>Once again, we will explore in lesson 1.9 why the F-test can be very useful.</li>
</ul>
<p><br></p>
<p><br></p>
<hr>
<p><a href="https://statsnotes.github.io">Homepage</a></p>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>