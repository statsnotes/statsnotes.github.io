<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Statistics for Social Scientists</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="4_files/libs/clipboard/clipboard.min.js"></script>
<script src="4_files/libs/quarto-html/quarto.js"></script>
<script src="4_files/libs/quarto-html/popper.min.js"></script>
<script src="4_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="4_files/libs/quarto-html/anchor.min.js"></script>
<link href="4_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="4_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="4_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="4_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="4_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: true
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body>

<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Statistics for Social Scientists</h1>
            <p class="subtitle lead">Lesson 1.4: Bivariate Regression - Estimation and Interpretation</p>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta">

      
    
      
    </div>
    
  
  </header><div id="quarto-content" class="page-columns page-rows-contents page-layout-article toc-left">
<div id="quarto-sidebar-toc-left" class="sidebar toc-left">
  <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="99">
    <h2 id="toc-title">Lesson 1.4: Simple Linear Regression - Estimation and Interpretation</h2>
   
  <ul class="collapse">
  <li><a href="#the-simple-linear-regression-model" id="toc-the-simple-linear-regression-model" class="nav-link active" data-scroll-target="#the-simple-linear-regression-model">1.4.1: The Simple Linear Regression Model</a></li>
  <li><a href="#fitted-values-and-best-fit-lines" id="toc-fitted-values-and-best-fit-lines" class="nav-link" data-scroll-target="#fitted-values-and-best-fit-lines">1.4.2: Fitted Values and Best-Fit Lines</a></li>
  <li><a href="#sum-of-squared-errors" id="toc-sum-of-squared-errors" class="nav-link" data-scroll-target="#sum-of-squared-errors">1.4.3: Sum of Squared Errors</a></li>
  <li><a href="#mathematics-of-the-ordinary-least-squares-estimator" id="toc-mathematics-of-the-ordinary-least-squares-estimator" class="nav-link" data-scroll-target="#mathematics-of-the-ordinary-least-squares-estimator">1.4.4: Mathematics of the Ordinary Least Squares Estimator</a></li>
  <li><a href="#interpretation-and-standardisation" id="toc-interpretation-and-standardisation" class="nav-link" data-scroll-target="#interpretation-and-standardisation">1.4.5: Interpretation and Standardisation</a></li>
  <li><a href="#r-squared-and-goodness-of-fit" id="toc-r-squared-and-goodness-of-fit" class="nav-link" data-scroll-target="#r-squared-and-goodness-of-fit">1.4.6: R-Squared and Goodness of Fit</a></li>
  <li><a href="#implementation-in-r" id="toc-implementation-in-r" class="nav-link" data-scroll-target="#implementation-in-r">Implementation in R</a>
  <ul class="collapse">
  <li><a href="#regression-estimation" id="toc-regression-estimation" class="nav-link" data-scroll-target="#regression-estimation">Regression Estimation</a></li>
  <li><a href="#plotting-relationships-graphically" id="toc-plotting-relationships-graphically" class="nav-link" data-scroll-target="#plotting-relationships-graphically">Plotting Relationships Graphically</a></li>
  </ul></li>
  </ul>
</nav>
</div>
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
</div>
<main class="content quarto-banner-title-block" id="quarto-document-content">





<p>This lesson covers the following topics:</p>
<ul>
<li>The basic form of the simple linear regression model (bivariate regression).</li>
<li>How we can mathematically estimate the slope and intercept of the best-fit line using the Ordinary Least Squares Estimator.</li>
<li>How we can interpret the OLS estimates as the relationships between two variables.</li>
<li>How we can describe the <em>goodness of fit</em> with the R-squared metric.</li>
<li>Why OLS is also the best approximation of the conditional expectation function.</li>
</ul>
<p><br></p>
<hr>
<p><a href="https://statsnotes.github.io">Homepage</a></p>
<section id="the-simple-linear-regression-model" class="level1">
<h1>1.4.1: The Simple Linear Regression Model</h1>
<p>In <a href="https://statsnotes.github.io/theory/3.html#magnitude-of-relationships-with-best-fit-lines">1.3.6</a>, we established that we care about the magnitude of the relationship between two variables <span class="math inline">x</span> and <span class="math inline">y</span>. One way we can measure the magnitude is through the slope of a best-fit linear line.</p>
<ul>
<li>This is because the slope in a linear equation <span class="math inline">y=mx+b</span> shows how much <span class="math inline">y</span> changes for every on unit increase in <span class="math inline">x</span>.</li>
</ul>
<p>We can formalise this with the Linear Regression Model:</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Definition: Simple Linear Regression
</div>
</div>
<div class="callout-body-container callout-body">
<p>The simple linear regression model takes the following form.</p>
<p><span class="math display">
y_i = \beta_0 + \beta_1 x_i + u_i
</span></p>
<ul>
<li>Where we have <span class="math inline">n</span> number of observations in our data, <span class="math inline">i</span> being any one of them, and each observation has an <span class="math inline">x</span> and <span class="math inline">y</span> value <span class="math inline">(x_i, y_i)</span>.</li>
<li>Where <span class="math inline">\beta_0</span> (intercept) and <span class="math inline">\beta_1</span> (slope) are coefficients of the model that need to be estimated (since they will differ in value between different samples and data).</li>
<li>Where <span class="math inline">\beta_1</span> (slope) describes the association of <span class="math inline">x</span> and <span class="math inline">y</span>.</li>
<li>Where <span class="math inline">u_i</span> is the error term (see below for more details)</li>
</ul>
<p>The simple linear regression model is also called the bivariate regression model, since there are two variables <span class="math inline">y</span> and <span class="math inline">x</span>.</p>
</div>
</div>
<p><br></p>
<p>You might notice an extra term at the end of the equation <span class="math inline">u_i</span>. This is called the error term. Why does it exist?</p>
<ul>
<li>Well, not all of our data points <span class="math inline">(x_i, y_i)</span> are going to be exactly on the straight line of best fit.</li>
<li>The term <span class="math inline">u_i</span> represents the distance (in terms of units of <span class="math inline">y</span>) of that actual point from the best-fit line.</li>
</ul>
<p>Mathematically, we can solve for the value of <span class="math inline">u_i</span> for each observation of <span class="math inline">u_i</span> by solving for it from the regression equation:</p>
<p><span class="math display">
\begin{split}
y_i &amp; = \beta_0 + \beta_1x_i + u_i \\
- u_i &amp; = -y_i + \beta_0 + \beta_1 x_i \\
u_i &amp; = y_i - \beta_0 - \beta_1 x_i
\end{split}
</span></p>
<p>This might not be too intuitive. An easier way is to visualise it with a figure. Take the figure below - not all points are on the best-fit line. <span class="math inline">u_i</span> represents the distance of points from the best fit line:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/clipboard-1210742477.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:55.0%"></p>
</figure>
</div>
<p>The error term, in social science terms, is the effect of anything else on <span class="math inline">y</span> excluding <span class="math inline">x</span> (which is already included in our linear equation).</p>
<ul>
<li>For example, if <span class="math inline">x</span> is age and <span class="math inline">y</span> is income, you might have a relationship between the two variables.</li>
<li>However, this is not a perfect linear relationship - not all points will be on the best fit line. This is because there are other factors that affect <span class="math inline">y</span> (income), including education, bargaining ability, location of work, and so on. It could also just be random variation - after all, some people’s incomes <span class="math inline">y</span> are a result of just pure luck.</li>
<li>Every other factor that affects <span class="math inline">y</span>, but is not <span class="math inline">x</span>, is encompassed in this error term <span class="math inline">u_i</span>.</li>
</ul>
<p>For the simple linear regression model, the average error <span class="math inline">u_i</span> across all observations <span class="math inline">i</span>, is 0. Mathematically, <span class="math inline">E(u_i) = 0</span>. We will discuss this in the <a href="https://statsnotes.github.io/theory/5.html">next lesson</a>.</p>
<p><br></p>
<p><br></p>
<hr>
<p><a href="https://statsnotes.github.io">Homepage</a></p>
</section>
<section id="fitted-values-and-best-fit-lines" class="level1">
<h1>1.4.2: Fitted Values and Best-Fit Lines</h1>
<p>We have discussed the form a simple linear regression takes: <span class="math inline">y_i = \beta_0 + \beta_1 x_i + u_i</span>.</p>
<p>However, that is not the best-fit line: we still need to estimate the coefficients <span class="math inline">\beta_0</span> (intercept) and <span class="math inline">\beta_1</span> (slope) in order to create a best-fit line.</p>
<ul>
<li>The estimates of <span class="math inline">\beta_0</span> and <span class="math inline">\beta_1</span> that we obtain will be denoted with a hat ^: <span class="math inline">\hat\beta_0</span> and <span class="math inline">\hat\beta_1</span>.</li>
<li>The estimates of <span class="math inline">\beta_0</span> and <span class="math inline">\beta_1</span> will vary depending on the data we have.</li>
</ul>
<p>We will discuss the estimation process in a short bit. But first, let us explore why we care about the estimates of our coefficients.</p>
<p><br></p>
<p>Once we have obtained our estimates of the coefficients, we will have a <strong>best-fit line</strong>, also called a <strong>fitted-values</strong> model.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Definition: Fitted Values
</div>
</div>
<div class="callout-body-container callout-body">
<p>The fitted values are obtained after estimating <span class="math inline">\beta_0</span> and <span class="math inline">\beta_1</span>. The equation takes the following form:</p>
<p><span class="math display">
\hat{y}_i = \hat\beta_0 + \hat\beta_1x_i
</span></p>
<ul>
<li>Where <span class="math inline">\hat{y}</span> are the predicted values of <span class="math inline">y</span> based on our best-fit line.</li>
<li>Where <span class="math inline">\hat\beta_0</span> and <span class="math inline">\hat\beta_1</span> are our estimates for the true coefficients <span class="math inline">\beta_0</span> and <span class="math inline">\beta_1</span>.</li>
<li>Note that the error term <span class="math inline">u_i</span> disappears. This is because the average value of <span class="math inline">u_i</span> is <span class="math inline">E(u_i) = 0</span>, so we do not need to include the term.</li>
</ul>
</div>
</div>
<p>What do the fitted values allow us to do?</p>
<p>The estimate <span class="math inline">\hat\beta_1</span> is the estimate of the slope of the linear equation.</p>
<ul>
<li>That means <span class="math inline">\hat\beta_1</span> explains the amount of change in <span class="math inline">y</span>, given a one unit increase in <span class="math inline">x</span>. If we are interested in describing the relationship between two variables, <span class="math inline">\hat\beta_1</span> is what we will focus on.</li>
</ul>
<p><span class="math inline">\hat y</span> is the predicted values of <span class="math inline">y</span>, which means we can also use the fitted values to make predictions. Just plug in values of <span class="math inline">x</span>, and the fitted values equation will output a prediction <span class="math inline">\hat y</span>.</p>
<ul>
<li>While this course does not focus on prediction, the subsequent course on Applied Machine Learning will dive much more into this topic.</li>
</ul>
<p>For example, let us say <span class="math inline">x</span> is age, and <span class="math inline">y</span> is income. Given any <span class="math inline">x</span> (age) value, we can predict the income value by plugging in <span class="math inline">x</span>. If we are interested in the income of a 30 year old, we would plug in 30 for <span class="math inline">x</span>:</p>
<p><span class="math display">
\hat y_i = \hat\beta_0 + \hat\beta_1(30)
</span></p>
<p>Of course, to actually calculate the <span class="math inline">\hat y</span>, we will need to estimate <span class="math inline">\hat \beta_0</span> and <span class="math inline">\hat\beta_1</span>.</p>
<p><br></p>
<p><br></p>
<hr>
<p><a href="https://statsnotes.github.io">Homepage</a></p>
</section>
<section id="sum-of-squared-errors" class="level1">
<h1>1.4.3: Sum of Squared Errors</h1>
<p>As I mentioned previously, to get a best-fit line, we need some way to estimate <span class="math inline">\beta_0</span> (intercept) and <span class="math inline">\beta_1</span> (slope) to get <span class="math inline">\hat\beta_0</span> and <span class="math inline">\hat\beta_1</span>.</p>
<p>The question is, how do we do this? For example, which best-fit line is better below - red, orange, or blue?</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/clipboard-1675702582.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></p>
</figure>
</div>
<p>To fit a best-fit line, we obviously want the line to fit the data well - i.e.&nbsp;have minimal errors compared to the actual data.</p>
<ul>
<li>What is an error? Recall that our original values of <span class="math inline">y</span> from the data for any observation <span class="math inline">i</span> are <span class="math inline">y_i</span>.</li>
<li>We also have predictions for the value of any observation from our best-fit line, labelled <span class="math inline">\hat y_i</span></li>
<li>Thus naturally, the error is how far away our prediction <span class="math inline">\hat y_i</span> is from the true observed value <span class="math inline">y_i</span>.</li>
</ul>
<p>One way we can fit an accurate line is to find the best-fit line that minimises the sum of squared errors (SSE).</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Definition: Sum of Squared Errors
</div>
</div>
<div class="callout-body-container callout-body">
<p>The sum of squared errors (SSE) is as follows:</p>
<p><span class="math display">
\begin{split}
SSE &amp; = \sum\limits_{i=1}^n (y_i - \hat y_i)^2 \\
&amp; = \sum\limits_{i=1}^n (y_i - \hat\beta_0 - \hat\beta_1 x_i)^2
\end{split}
</span></p>
<ul>
<li>The sum of squared errors is exactly as it sounds. Find the error, the distance between the actual <span class="math inline">y_i</span> and predicted <span class="math inline">\hat y</span>, which is <span class="math inline">y_i - \hat y</span>, then square that error <span class="math inline">(y_i - \hat y_i)^2</span>, then sum up for all observations <span class="math inline">i</span> in the data.</li>
<li>We get the second equation by substituting in the fitted values model (discussed in the previous section), where <span class="math inline">\hat{y} = \hat\beta_0 + \hat\beta_1x_i</span>.</li>
</ul>
</div>
</div>
<p>More inuitively, the errors of a best-fit line are highlighted in red. We will square each error, then sum all the errors up, to get the sum of squared errors for that best-fit line:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/clipboard-846785636.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:75.0%"></p>
</figure>
</div>
<p>Why do we want to square the errors?</p>
<ul>
<li>This is because we do not care about the direction of errors - only the size of the errors.</li>
<li>For example, the error in the above figure <em>d1</em> is positive, while <em>d2</em> is negative. If we sum them together, those almost cancel out, giving us an error of near zero. However, we do not want them to be cancelled out - we ace about the sizes of the errors.</li>
<li>Thus, by squaring the errors, we make all errors positive, thus only focusing on the size of the errors, not their positive/negative direction.</li>
</ul>
<p>A common question is why we square the errors, and don’t use absolute values of the errors. There are a few reasons this is the case.</p>
<ol type="1">
<li>As we will see in the next section, minimising functions relies on finding the derivative of the function. An absolute value function is not differentiable at its vertex, making it difficult to minimise (as we are trying to minimise the errors).</li>
<li>The least-squares method has several desirable properties for inference that we will cover mostly in the next lesson.</li>
</ol>
<p><br></p>
<p><br></p>
<hr>
<p><a href="https://statsnotes.github.io">Homepage</a></p>
</section>
<section id="mathematics-of-the-ordinary-least-squares-estimator" class="level1">
<h1>1.4.4: Mathematics of the Ordinary Least Squares Estimator</h1>
<p>The Ordinary Least Squares (OLS) Estimator estimates the coefficients <span class="math inline">\beta_0</span> and <span class="math inline">\beta_1</span> by finding the values of <span class="math inline">\hat\beta_0</span> and <span class="math inline">\hat\beta_1</span> that result in the line with the smallest sum of squared errors (as discussed in the last section).</p>
<p>We can describe the goal of OLS in a more mathematical way:</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Definition: Ordinary Least Squares (OLS) Estimator
</div>
</div>
<div class="callout-body-container callout-body">
<p>The goal of the Ordinary Least Squares (OLS) Estimator is to find the values of <span class="math inline">\beta_0</span> and <span class="math inline">\beta_1</span> that make the following statement true:</p>
<p><span class="math display">
\begin{split}
(\hat{\beta}_0, \hat{\beta}_1) &amp; = \min\limits_{\hat{\beta}_0, \hat{\beta}_1} \sum\limits_{i=1}^n (y_i - \hat{\beta}_0 - \hat{\beta}_1x_i)^2 \\
&amp; =\min\limits_{\hat{\beta_0}, \hat{\beta}_1} S(\hat{\beta}_0, \hat{\beta}_1)
\end{split}
</span></p>
<p>Where function <span class="math inline">S</span> is the sum of squared errors.</p>
</div>
</div>
<p><br></p>
<p>How do we minimise <span class="math inline">S</span> (the function of the sum of squared errors)?</p>
<ul>
<li>From calculus, we know that a minimum/maximum of a function is where the derivative of the function is equal to 0.</li>
</ul>
<p>Thus, let us find the partial derivative of the function <span class="math inline">S</span> in respect to both <span class="math inline">\hat\beta_0</span> and <span class="math inline">\hat\beta_1</span>, and set them equal to 0. This is also called the <strong>first-order conditions</strong>.</p>
<p><br></p>
<section id="first-order-conditions" class="level3">
<h3 class="anchored" data-anchor-id="first-order-conditions">First Order Conditions</h3>
<p>First, let us find the partial derivative of <span class="math inline">S</span> in respect to <span class="math inline">\hat\beta_0</span>:</p>
<p><span class="math display">
\frac{\partial S(\hat{\beta}_0, \hat{\beta}_1)}{\partial \hat{\beta}_0} = \frac{\partial }{\partial \hat{\beta}_0} \left[ \sum\limits_{i=1}^n (y_i - \hat{\beta}_0 - \hat{\beta}_1x_i)^2 \right]
</span></p>
<p>First, ignore the summation. The partial derivative of the internal section, using chain rule, is the following:</p>
<p><span class="math display">
\frac{\partial}{\partial \hat{\beta}_0} \left[ (y_i - \hat{\beta}_0 - \hat{\beta}_1 x_i)^2 \right] = -2(y_i - \hat{\beta}_0 - \hat{\beta}_1 x_i)
</span></p>
<p>But how do we deal with the summation? We know that there is the sum rule of derivatives <span class="math inline">[f(x) + g(x)]' = f'(x) + g'(x)</span>. Thus, we know we just sum up the derivatives to get the derivative:</p>
<p><span class="math display">
\begin{split}
\frac{\partial S(\hat{\beta}_0, \hat{\beta}_1)}{\partial \hat{\beta}_0} &amp; = \sum\limits_{-i=1}^n \left[ -2(y_i - \hat{\beta}_0 - \hat{\beta}_1 x_i) \right] \\
&amp; = -2 \sum\limits_{i=1}^n (y_i - \hat{\beta}_0 - \hat{\beta}_1 x_i)
\end{split}
</span></p>
<p>To find the value of <span class="math inline">\hat\beta_0</span> that minimises <span class="math inline">S</span>, we set the derivative equal to 0. We can ignore the -2, since if the summation is equal to 0, the whole derivative will equal 0. Thus, the first order condition is:</p>
<p><span class="math display">
\sum\limits_{i=1}^n (y_i - \hat{\beta}_0 - \hat{\beta}_1 x_i) = 0
</span></p>
<p><br></p>
<p>Now, let us do the same for <span class="math inline">\hat\beta_1</span>. Using the same steps as before</p>
<p><span class="math display">
\begin{split}
\frac{\partial S(\hat{\beta}_0, \hat{\beta}_1)}{\partial \hat{\beta}_1} &amp; = \sum\limits_{i=1}^n \left[ -2x_i(y_i - \hat{\beta}_0 - \hat{\beta}_1 x_i) \right] \\
&amp; = -2 \sum\limits_{i=1}^n x_i(y_i - \hat{\beta}_0 - \hat{\beta}_1 x_i)
\end{split}
</span></p>
<p>The first order condition for <span class="math inline">\hat\beta_1</span> will be (again, ignoring the -2 for the same reason as before):</p>
<p><span class="math display">
\sum\limits_{i=1}^n x_i(y_i - \hat{\beta}_0 - \hat{\beta}_1 x_i) = 0
</span></p>
<p><br></p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Definition: First Order Conditions of OLS
</div>
</div>
<div class="callout-body-container callout-body">
<p>Thus, the first order conditions of OLS are:</p>
<p><span class="math display">
\begin{split}
&amp; \sum\limits_{i=1}^n (y_i - \hat{\beta}_0 - \hat{\beta}_1 x_i) = 0 \\
&amp; \sum\limits_{i=1}^n x_i (y_i - \hat{\beta}_0 - \hat{\beta}_1 x_i) = 0
\end{split}
</span></p>
</div>
</div>
<p><br></p>
</section>
<section id="solving-the-system-of-equations" class="level3">
<h3 class="anchored" data-anchor-id="solving-the-system-of-equations">Solving the System of Equations</h3>
<p>We now have our two first-order conditions. Now, we basically have a 2-equation system of equations, with 2 variables.</p>
<ul>
<li>We can solve this through substitution - in the first equation, solve for <span class="math inline">\hat\beta_0</span> in terms of <span class="math inline">\hat\beta_1</span>.</li>
<li>Then, plug in <span class="math inline">\hat\beta_0</span> in terms of <span class="math inline">\hat\beta_1</span> into the second equation, thus making that a one-variable equation. We can solve that equation for <span class="math inline">\hat\beta_1</span>, then find <span class="math inline">\hat\beta_0</span>.</li>
</ul>
<p><br></p>
<p>First, let us solve the first equation for <span class="math inline">\hat\beta_0</span> in terms of <span class="math inline">\hat\beta_1</span>:</p>
<p><span class="math display">
\begin{split}\sum\limits_{i=1}^n (y_i - \hat{\beta}_0 - \hat{\beta}_1 x_i) &amp; =  0 \\
\sum\limits_{i=1}^n y_i - n \hat{\beta}_0 - \hat{\beta}_1 \sum\limits_{i=1}^n x_i &amp; = 0 \\
-n\hat{\beta}_0 &amp;= -\sum\limits_{i=1}^n y_i + \hat{\beta}_1\sum\limits_{i=1}^nx_i \\
\hat{\beta}_0 &amp; = \frac{1}{n} \sum\limits_{i=1}^n y_i - \frac{1}{n}\hat{\beta}_1 \sum\limits_{i=1}^n x_i \\
&amp; = \bar{y} - \hat{\beta}_1 \bar{x}
\end{split}
</span></p>
<p>Now, let us substitute our calculated <span class="math inline">\hat{\beta}_0 = \bar{y} - \hat{\beta}_1 \bar{x}</span> into the <span class="math inline">\hat{\beta}_1</span> condition and solve for <span class="math inline">\hat{\beta}_1</span>:</p>
<p><span class="math display">
\begin{split}
0 &amp; =\sum\limits_{i=1}^n x_i (y_i - \hat{\beta}_0 - \hat{\beta}_1 x_i)  \\
&amp; = \sum\limits_{i=1}^n \left[ x_i(y_i - [\bar{y} - \hat{\beta}_1\bar{x}] - \hat{\beta}_1x_i) \right] \\
&amp; = \sum\limits_{i=1}^n \left[ x_i(y_i - \bar{y} - \hat{\beta}_1 (x_i - \bar{x})) \right] \\
&amp; = \sum\limits_{i=1}^n \left[ x_i(y_i - \bar{y}) - x_i \hat{\beta}_1(x_i - \bar{x}) \right] \\
&amp; = \sum\limits_{i=1}^n x_i (y_i - \bar{y}) - \hat{\beta}_1 \sum\limits_{i=1}^nx_i (x_i - \bar{x})
\end{split}
</span></p>
<p><br></p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Useful Properties of Summation
</div>
</div>
<div class="callout-body-container callout-body">
<p>Before we finish, here are a few key properties of summation</p>
<p><strong>Property 1:</strong></p>
<p><span class="math display">
\sum\limits_{i=1}^n (x_i - \bar{x}) = 0
</span></p>
<ul>
<li>This is because we can expand the left to <span class="math inline">\sum x_i - \sum \bar x</span>.</li>
<li>Then, we know <span class="math inline">\sum x_i = \sum \bar x</span> (by the formula for mean), so <span class="math inline">\sum x_i - \sum \bar x = 0</span>.</li>
</ul>
<p><strong>Property 2:</strong></p>
<p><span class="math display">
\sum\limits_{i=1}^n x_i(y_i - \bar{y}) = \sum\limits_{i=1}^n(x_i - \bar{x}) (y_i - \bar{y})
</span></p>
<ul>
<li>This is because on the right side can expand to <span class="math inline">\sum [x_i(y_i - \bar y) - \bar x (y_i - \bar y)]</span>.</li>
<li>Then, split into <span class="math inline">\sum x_i (y_i - \bar y) - \bar x \sum (y_i - \bar y)</span>.</li>
<li>We know that by property 1 (which applies to any variable), <span class="math inline">\sum (y_i - \bar y) = 0</span>. Thus, the right side disappears, and we are left with <span class="math inline">\sum x_i (y_i - \bar y)</span>.</li>
</ul>
<p><strong>Property 3:</strong></p>
<p><span class="math display">
\sum\limits_{i=1}^n x_i(x_i - \bar{x}) = \sum\limits_{i=1}^n(x_i - \bar{x})^2
</span></p>
<ul>
<li>Start by expanding right side to <span class="math inline">\sum [ x_i ( x_i - \bar x) - \bar x (x_i - \bar x)]</span></li>
<li>Which splits into <span class="math inline">\sum x_i (x_i - \bar x) - \bar x \sum (x_i - \bar x)</span></li>
<li>By the first property, we know <span class="math inline">\sum x_i - \bar x = 0</span>, so we are only left with <span class="math inline">\sum x_i (x_i - \bar x)</span></li>
</ul>
</div>
</div>
<p><br></p>
<p>Knowing these properties of summation, we can transform what we had before:</p>
<p><span class="math display">
\begin{split}
0 &amp; = \sum\limits_{i=1}^n x_i (y_i - \bar{y}) - \hat{\beta}_1 \sum\limits_{i=1}^nx_i (x_i - \bar{x}) \\
0 &amp; = \sum\limits_{i=1}^n(x_i - \bar{x})(y_i - \bar{y}) - \hat{\beta}_1 \sum\limits_{i=1}^n (x_i - \bar{x})^2 \\
\hat{\beta}_1 \sum\limits_{i=1}^n (x_i - \bar{x})^2 &amp; = \sum\limits_{i=1}^n(x_i - \bar{x})(y_i - \bar{y}) \\
\hat{\beta}_1 &amp; = \frac{\sum_{i=1}^n (x_i - \bar{x})(y_i - \bar{y})}{\sum_{i=1}^n(x_i - \bar{x})^2}
\end{split}
</span></p>
<p>Note that the numerator is equivalent to the formula of covariance <span class="math inline">Cov(x,y)</span>, and the denominator is equal to the variance <span class="math inline">Var(x)</span>.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Definition: OLS Estimate of Coefficient
</div>
</div>
<div class="callout-body-container callout-body">
<p>Thus, the OLS estimate <span class="math inline">\hat\beta_1</span> (slope) of the linear regression model is:</p>
<p><span class="math display">
\hat{\beta}_1 = \frac{\sum_{i=1}^n (x_i - \bar{x})(y_i - \bar{y})}{\sum_{i=1}^n(x_i - \bar{x})^2} = \frac{Cov(x, y)}{Var(x)}
</span></p>
<p>This is the expected change in <span class="math inline">y</span> given a one unit increase in <span class="math inline">x</span>.</p>
<ul>
<li>Remember, this is the <strong>relationship</strong> between <span class="math inline">x</span> and <span class="math inline">y</span>, <u><strong>not</strong> the causal effect</u>.</li>
</ul>
</div>
</div>
<p><br></p>
<p>Of course, we still need to find <span class="math inline">\hat\beta_0</span> (the slope). We found that <span class="math inline">\hat\beta_0 = \bar{y} - \hat{\beta}_1 \bar{x}</span> earlier, so we just plug our solution of <span class="math inline">\hat\beta_1</span> in.</p>
<p>And now, we have our estimates <span class="math inline">\hat\beta_0</span> and <span class="math inline">\hat\beta_1</span>, and thus we now have a best-fit line and an estimate of the relationship between <span class="math inline">x</span> and <span class="math inline">y</span>.</p>
<p>Note: in the <a href="https://statsnotes.github.io/theory/5.html">next lesson</a>, we will discuss if the OLS estimator is a good estimator or not. For now, we just care about the mechanics of the estimator.</p>
<p><br></p>
<p><br></p>
<hr>
<p><a href="https://statsnotes.github.io">Homepage</a></p>
</section>
</section>
<section id="interpretation-and-standardisation" class="level1">
<h1>1.4.5: Interpretation and Standardisation</h1>
<p>We now have estimated <span class="math inline">\hat\beta_0</span> and <span class="math inline">\hat\beta_1</span>. But what do these actually mean in the context of the relationship between <span class="math inline">x</span> and <span class="math inline">y</span>?</p>
<ul>
<li>Let us start with <span class="math inline">\hat\beta_1</span>, which is the slope, the more important of the two coefficients.</li>
</ul>
<p><br></p>
<section id="interpretation-of-hatbeta_1" class="level3">
<h3 class="anchored" data-anchor-id="interpretation-of-hatbeta_1">Interpretation of <span class="math inline">\hat\beta_1</span></h3>
<p>We know that in a linear fitted-values model, <span class="math inline">\hat y_i = \hat\beta_0 + \hat\beta_1 x_i</span>, the coefficient <span class="math inline">\beta_1</span> is the slope.</p>
<ul>
<li>And the slope is the change in <span class="math inline">y</span> given a one unit increase in <span class="math inline">x</span>.</li>
</ul>
<p>Using this knowledge, we can interpret estimate <span class="math inline">\hat\beta_1</span>.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Interpretation of <span class="math inline">\hat\beta_1</span>
</div>
</div>
<div class="callout-body-container callout-body">
<p>When <span class="math inline">x</span> increases by one unit, there is an expected <span class="math inline">\hat{\beta}_1</span> unit change in <span class="math inline">y</span>.</p>
</div>
</div>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning!
</div>
</div>
<div class="callout-body-container callout-body">
<p>Note how I have been using the word <strong>relationship</strong>, not causal effect.</p>
<p>Causality is not established through estimators, it is established through a strong experimental design (which we will cover in part II of the course).</p>
</div>
</div>
<p>Note that this interpretation of <span class="math inline">\hat\beta_1</span> only applies to continuous <span class="math inline">x</span> variables and continuous/ordinal <span class="math inline">y</span> variables. We will discuss interpretation with categorical/binary variables in lesson 1.9.</p>
<p><br></p>
</section>
<section id="interpretation-of-hatbeta_0" class="level3">
<h3 class="anchored" data-anchor-id="interpretation-of-hatbeta_0">Interpretation of <span class="math inline">\hat\beta_0</span></h3>
<p>We know that in a linear fitted-values model, <span class="math inline">\hat y_i = \hat\beta_0 + \hat\beta_1 x_i</span>, the coefficient <span class="math inline">\beta_0</span> is the y-intercept.</p>
<ul>
<li>And the y-intercept is the change value of <span class="math inline">y</span> given <span class="math inline">x=0</span>.</li>
</ul>
<p>We can prove this mathematically:</p>
<p><span class="math display">
\begin{split}
\hat y_{i, \ x_i = 0} &amp; = \hat\beta_0 + \hat\beta_1 x_i \\
&amp; = \hat\beta_0 + \hat\beta_1(0) \\
&amp; = \hat\beta_0
\end{split}
</span></p>
<p>Thus, knowing this, we can interpret <span class="math inline">\hat\beta_0</span>.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Interpretation of <span class="math inline">\hat\beta_0</span>
</div>
</div>
<div class="callout-body-container callout-body">
<p>When <span class="math inline">x=0</span>, the expected value of <span class="math inline">y</span> is <span class="math inline">\hat{\beta}_0</span></p>
</div>
</div>
<p><br></p>
</section>
<section id="standardising-beta_1-in-terms-of-standard-deviations" class="level3">
<h3 class="anchored" data-anchor-id="standardising-beta_1-in-terms-of-standard-deviations">Standardising <span class="math inline">\beta_1</span> in Terms of Standard Deviations</h3>
<p>Sometimes, it is hard to understand what changes in <span class="math inline">y</span> and <span class="math inline">x</span> mean in terms of units. For example, if we are measuring “democracy”, what does a 5 unit change in democracy mean? Is that a lot?</p>
<p>We can add more relevant detail by expressing the change of <span class="math inline">y</span> and <span class="math inline">x</span> in standard deviations.</p>
<p>How do we calculate this? Well, let us solve for the change in <span class="math inline">\hat{y}_i/\sigma_y</span> given <span class="math inline">x_i = x</span> and <span class="math inline">x = x + \sigma_X</span>. This will tell us how much <span class="math inline">\hat{y}</span> changes by given a increase of one standard deviation in <span class="math inline">x</span>:</p>
<p><span class="math display">
\begin{split}
\frac{\hat y_{i, \ x_i = x + \sigma_x}}{\sigma_y} - \frac{\hat y_{i, \ x_i = x}}{\sigma_y} &amp; = \frac{\hat\beta_0 + \hat\beta_1 x_i}{\sigma_y} - \frac{\hat\beta_0 + \hat\beta_1 x_i}{\sigma_y} \\
&amp; = \frac{\hat\beta_0 + \hat\beta_1 (x+\sigma_x) - (\hat\beta_0 + \hat\beta_1 (x))}{\sigma_y} \\
&amp; = \frac{\hat\beta_0 - \hat\beta_0 + \hat\beta_1x - \hat\beta_1x+\hat\beta_1\sigma_x}{\sigma_y} \\
&amp; = \frac{\hat\beta_1 \sigma_x}{\sigma_y}
\end{split}
</span></p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Interpretation in Terms of Standard Deviation
</div>
</div>
<div class="callout-body-container callout-body">
<p>For a one-std. deviation increase in <span class="math inline">x</span>, there is an expected <span class="math inline">\hat{\beta}_1 \sigma_x / \sigma_y</span>-std. deviation change in <span class="math inline">Y</span>.</p>
</div>
</div>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning!
</div>
</div>
<div class="callout-body-container callout-body">
<p>Note how I have been using the word <strong>relationship</strong>, not causal effect.</p>
<p>Causality is not established through estimators, it is established through a strong experimental design (which we will cover in part II of the course).</p>
</div>
</div>
<p><br></p>
<p><br></p>
<hr>
<p><a href="https://statsnotes.github.io">Homepage</a></p>
</section>
</section>
<section id="r-squared-and-goodness-of-fit" class="level1">
<h1>1.4.6: R-Squared and Goodness of Fit</h1>
<p>For each observation, we know that the actual <span class="math inline">y_i</span> value is the predicted <span class="math inline">\hat y_i</span> plus the residual term <span class="math inline">\hat u_i</span>. Thus:</p>
<p><span class="math display">
y_i = \hat y_i + \hat u_i
</span></p>
<p>Now, let us define these three concepts: the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR):</p>
<p><span class="math display">
\begin{split}
&amp; SST = \sum\limits_{i=1}^n (y_i - \bar y)^2 \\
&amp; SSE = \sum\limits_{i=1}^n (\hat y_i - \bar y)^2 \\
&amp; SSR = \sum\limits_{i=1}^n (\hat u_i)^2
\end{split}
</span></p>
<ul>
<li>The SST explains the total amount of variation in <span class="math inline">y</span></li>
<li>The SSE is the amount of variation in <span class="math inline">y</span> explained by our model</li>
<li>The SSR is the amount of variation in <span class="math inline">y</span> not explained by our model</li>
</ul>
<p>Let us look at the total sum of squares (SST). We can manipulate it as follows:</p>
<p><span class="math display">
\begin{split}
SST &amp; = \sum\limits_{i=1}^n (y_i - \bar y)^2 \\
&amp; = \sum\limits_{i=1}^n(y_i - \hat y_i+ \hat y_i - \bar y)^2 \\
&amp; = \sum\limits_{i=1}^n((y_i - \hat y_i)+ \hat y_i - \bar y)^2 \\
&amp; = \sum\limits_{i=1}^n[\hat u_i + \hat y_i - \bar y]^2 \\
&amp; = \sum\limits_{i=1}^n[\hat u_i^2 + \hat u_i \hat y_i - \hat u_i \bar y + \hat y_i \hat u_i + \hat y_i^2 - \hat y_i \bar y-\bar y \hat u_i -\bar y \hat  y_i+\hat y^2_i] \\
&amp; = \sum\limits_{i=1}^n[ \hat u_i^2 + 2 \hat u_i \hat y_i+ \hat y_i^2 - 2 \hat u_i \bar y - 2 \hat y_i \bar y + \bar y ^2]
\end{split}
</span></p>
<p>And since we know <span class="math inline">\sum \hat y_i \hat u_i = 0</span>, we can further simplify to:</p>
<p><span class="math display">
\begin{split}
SST &amp; = \sum\limits_{i=1}^n[ \hat u_i^2 + \hat y_i^2 - 2 \hat u_i \bar y - 2 \hat y_i \bar y + \bar y ^2] \\
&amp; = \sum\limits_{i=1}^n[\hat u_i^2 + (\hat y_i - \bar y)^2]\\
&amp; = \sum\limits_{i=1}^n \hat u_i^2 + \sum\limits_{i=1}^n(\hat y_i - \bar y)^2 \\
&amp; = SSE + SSR
\end{split}
</span></p>
<p>This makes sense: After all, SSE is the squared errors explained by the model, and SSR is the residual (non-explained) parts of the model, so together, they should be equal to the total sum of squares.</p>
<p><br></p>
<p>Using these properties, we can create a statistic which explains how well our model explains the variation in <span class="math inline">y</span>. This statistic is called <span class="math inline">R^2</span>.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Definition: R-Squared
</div>
</div>
<div class="callout-body-container callout-body">
<p>The R-squared metric is a metric describing how good of a fit our model is. Mathematically:</p>
<p><span class="math display">
R^2 = \frac{SSE}{SST} = 1 - \frac{SSR}{SST}
</span></p>
<p>What does this <span class="math inline">R^2</span> value mean?</p>
<ul>
<li>Well SSE is the amount of variation in <span class="math inline">y</span> explained by our model, and SST is the total amount of variation in <span class="math inline">y</span>.</li>
<li>Thus, <span class="math inline">R^2</span> is the proportion of variation in <span class="math inline">y</span> explained by our model.</li>
</ul>
</div>
</div>
<p><span class="math inline">R^2</span> is always between 0 and 1:</p>
<ul>
<li>This is because it is a proportion, so and <span class="math inline">0 ≤ SSE ≤ SST</span>, so this must be true.</li>
<li>Values closer to 1 mean our model explains the variance in <span class="math inline">y</span> more</li>
<li>Values closer to 0 mean our model explains less of the variance in <span class="math inline">y</span>.</li>
</ul>
<p>However, be careful when using <span class="math inline">R^2</span>. Just because it is high, does not mean we can infer anything from it.</p>
<p>Extra notes about <span class="math inline">R^2</span>:</p>
<ul>
<li><span class="math inline">R^2</span> is also equal to the correlation coefficient between <span class="math inline">y_i</span> and <span class="math inline">\hat y_i</span>.</li>
<li>In simple linear regression, <span class="math inline">R^2</span> is also equal to the square of the correlation coefficient <span class="math inline">r</span> between <span class="math inline">x</span> and <span class="math inline">y</span>.</li>
</ul>
<p><br></p>
<p><br></p>
<hr>
<p><a href="https://statsnotes.github.io">Homepage</a></p>
</section>
<section id="implementation-in-r" class="level1">
<h1>Implementation in R</h1>
<section id="regression-estimation" class="level2">
<h2 class="anchored" data-anchor-id="regression-estimation">Regression Estimation</h2>
<p>To estimate a regression, we can use the <em>feols()</em> function from the package <em>fixest</em>, or we can use the base-R function <em>lm()</em>.</p>
<ul>
<li>The syntax is the same for both (at least for simple linear regression).</li>
<li>The <em>feols()</em> function does have a few advantages for techniques that will be discussed later, especially when it comes to causal inference and econometrics.</li>
</ul>
<p>For the <em>feols()</em> function, we will need the <em>fixest</em> package. Make sure to install it if you have not previously (google how to install R-packages if needed).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(fixest)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><br></p>
<p><strong>Syntax:</strong></p>
<p>For the <em>feols()</em> function, the syntax is as follows:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">feols</span>(y <span class="sc">~</span> x, <span class="at">data =</span> mydata)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ul>
<li>Replace <em>model</em> with any name you want to store your regression model in.</li>
<li>Replace <em>y</em> with your outcome variable name, and <em>x</em> with your explanatory variable name.</li>
<li>Replace <em>mydata</em> with the name of your dataframe.</li>
</ul>
<p>The <em>lm()</em> function has the exact same syntax for simple linear regression, except that we replace <em>feols()</em> with <em>lm()</em>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x, <span class="at">data =</span> mydata)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><br></p>
<p><strong>Example:</strong></p>
<p>Let us run a regression with outcome variable <em>immatt</em> (attitude towards immigrants), explanatory variable <em>age</em>, from the dataframe called <em>dta</em>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>my_model <span class="ot">&lt;-</span> <span class="fu">feols</span>(immatt <span class="sc">~</span> age, <span class="at">data =</span> dta)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(my_model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>OLS estimation, Dep. Var.: immatt
Observations: 33,706
Standard-errors: IID 
             Estimate Std. Error  t value  Pr(&gt;|t|)    
(Intercept)  0.477238   0.015811  30.1830 &lt; 2.2e-16 ***
age         -0.008401   0.000291 -28.8857 &lt; 2.2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
RMSE: 0.961932   Adj. R2: 0.024129</code></pre>
</div>
</div>
<p>We can see in the estimate column, we get our intercept estimate <span class="math inline">\hat\beta_0</span>, and our explanatory variable coefficient estimate <span class="math inline">\hat\beta_1</span>.</p>
<p>The result is similar with <em>lm()</em>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>my_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(immatt <span class="sc">~</span> age, <span class="at">data =</span> dta)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(my_model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = immatt ~ age, data = dta)

Residuals:
     Min       1Q   Median       3Q      Max 
-2.75282 -0.61715  0.07398  0.66244  2.30046 

Coefficients:
              Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  0.4772381  0.0158115   30.18   &lt;2e-16 ***
age         -0.0084011  0.0002908  -28.89   &lt;2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.962 on 33704 degrees of freedom
Multiple R-squared:  0.02416,   Adjusted R-squared:  0.02413 
F-statistic: 834.4 on 1 and 33704 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p><br></p>
</section>
<section id="plotting-relationships-graphically" class="level2">
<h2 class="anchored" data-anchor-id="plotting-relationships-graphically">Plotting Relationships Graphically</h2>
<p>We can plot relationships between two variables using a scatterplot. For this, we will need the <em>tidyverse package</em>. Make sure to install it if you have not previously (google how to install R-packages if needed).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><br></p>
<p><strong>Syntax:</strong></p>
<p>We can create scatterplots with the <em>ggplot()</em> function as follows:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(mydata, <span class="fu">aes</span>(<span class="at">x =</span> x_variable, <span class="at">y =</span> y_variable)) <span class="sc">+</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> lm)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ul>
<li>Replace <em>mydata</em> with the name of your dataframe that contains your variables.</li>
<li>Replace <em>x_variable</em> with the name of the variable you want displayed on the <span class="math inline">x</span> axis.</li>
<li>Replace <em>y_variable</em> with the name of the variable you want displayed on the <span class="math inline">y</span> axis.</li>
</ul>
<p>Note: the <em>geom_point()</em> part plots the points on the scatterplot, and the <em>geom_smooth()</em> part plots the best-fit line (OLS estimation).</p>
<ul>
<li>The <em>method = lm</em> within the <em>geom_smooth()</em> tells us to use OLS estimation in the best-fit line.</li>
</ul>
<p><br></p>
<p><strong>Example:</strong></p>
<p>Let us do a scatterplot on the variable <em>age</em> and the variable <em>immatt</em> (immigration attitude), both variables being contained in the dataframe named <em>dta</em>:</p>
<ul>
<li>I added <em>theme_bw()</em>, which is a theme in ggplot (see appendix B).</li>
<li>I added the argument <em>size=0</em>, as this allows us to control for the size of the dots.</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(dta, <span class="fu">aes</span>(<span class="at">x =</span> age, <span class="at">y =</span> immatt)) <span class="sc">+</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="dv">0</span>) <span class="sc">+</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> lm) <span class="sc">+</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>`geom_smooth()` using formula = 'y ~ x'</code></pre>
</div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="4_files/figure-html/unnamed-chunk-9-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Obviously, there are way too many observations in this scatterplot, but this will look nicer for a plot with less observations.</p>
<p><br></p>
<p><br></p>
<hr>
<p><a href="https://statsnotes.github.io">Homepage</a></p>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>